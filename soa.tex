\chapter{State of the Art}
\label{cha:soa}

In this chapter the state of the art in dealing with life events on social media is presented, starting with what the research has done so far to detect them, and explaining also the current situation with data in this field.

Event detection using social networks is a common practice. The literature offers many example of event detection on a global scale based on the analysis of social media contents, such as real-time earthquake identification based on tweets \cite{sakaki2010earthquake}, breaking news discovery in Twitter \cite{jackoway2011identification, phuvipadawat2010breaking}, or big gigs recognition observing what is posted on Flickr \cite{liu2011using}.

Event prediction using social network contents is also pretty common: the most striking example of the last few years are the 2016 american elections. In fact, while many of the official polls made by the most famous american newspapers and televisions had always forecasted Hillary Clinton as winner, social media reactions had been increasingly in favor of the Republicans during the election campaign\footnote{\url{techcrunch.com/2016/11/10/social-media-did-a-better-job-at-predicting-trumps-win-than-the-polls}}, and the rest is history. Other cases of event prediction using social media are, for example, movie box-office \cite{asur2010predicting} or Oscar-winner forecasts.

There is much less literature about life-event detection on social media, and it is almost completely focused on post classification. Another important issue about life events is related with data: it's hard to find it, and in a machine learning scenario like this problem data play a key role.

\section{Life event detectors on social media}
\label{sec:socialmediadetectors}
Almost all the models proposed by the literature are classifiers that take a textual post as input and give as output a label, indicating whether the text talks about a life event. Each classifier is specialized to a single life event, for example a detector of posts about weddings. Some models are focused on a single post at a time, while few others \cite{cavalin2015multiple, moyanolife} consider also the conversation linked to the main post to understand the context and the importance of the speech. The feature extraction is done mainly in two ways: working only with the text itself, using bag-of-words or bag-of-N-grams \cite{cavalinclassification, di2013detecting, li2014major}, or using a semantic analyzer, to combine the previous method with semantic information, such as sentiment score, formality with which the text is written, entities and topics contained, etc \cite{khobarekar2013detecting}. In addition to that, some models consider also \emph{external} features, like user's features (number of friends, age, location, post frequency, etc.) or post success \cite{dickinson2015identifying}.

All these models have several weaknesses for the purpose of this thesis, which are briefly described now. First of all, they just give a piece of information, saying whether a post is about or not to a life event, and they don't go further with it. Secondly, there is no consideration of the user's timeline, of her behavior on social media, and no comparison with other posts published by the same user: in fact the samples used in papers are fetched more or less randomly from the social networks, without any user profiling intent, and consequently each post analyzed is completely disconnected with the other ones. Furthermore, analysing contents in this way there is no perception of how much the event may have lasted, and it is not understandable whether the event was in the past and now it's over, is just passed, it's occurring or it's coming in the near future. Another point worth of noting is that a post related to a life event may not be concerned with the author (e.g. participate in a wedding instead of getting married), or a post classified as about a life event could be a false positive: in both cases the decision to say that this person has lived a life event is based only on a single content, and this is a result of not consider the user's timeline. Thirdly, only text contents are considered: however, according to Mark Zuckerberg, CEO and founder of Facebook, "\textit{Most of the content 10 years ago was text, and then photos, and now it's quickly becoming videos}"\footnote{\url{www.fastcompany.com/3057024/mark-zuckerberg-soon-the-majority-of-content-we-consume-will-be-video}}. Not only are posts composed by more than only text, but many of them have no text at all. Furthermore, the meaning of an image or a video can give a strong clue to understand what the post is about: for example, an image containing a pink ribbon can easily be interpreted as a female baby announcement, without even look at the text. Last but not least, every model cited above uses Twitter contents only: this platform allows to share texts with at most 280 characters (until late 2017 the limit was 140) and it is used more for business purposes rather than personal life sharing. On the other hand, most of the contents on this social network are free to access and to obtain for non-commercial purposes, without having an explicit user authorization.

\subsection{A step further}
The literature offers a model that goes a step further of those highlighted above: the work made by Cavalin, Gatti, Pinharez for the \emph{IBM InfoSphere BigInsights} platform \cite{cavalin2014towards}. Starting from life event classification on a sample of tweets, it performs a user entity matching on an existing database of clients, aimed to decide which is the best approach to offer them some services or some products. Once a user that texts about a life event is identified, her information are used to match her into a database of clients.

In common with our model there is a big move forward from a simple classifier, but with an important difference: it solves the reverse problem of ours. Its goal is to get a list of users that posted about a life event in a given time window, while ours is to understand if a user has posted about a life event and in which time period. In this paper a wide range of posts written by many authors is taken to analyse the presence of a life event, not considering user's timeline at all, while our model is focused on a single user analysis. This brings all the problems highlighted above in the previous section. Furthermore, also this model is  concentrated only on Twitter contents.

\section{Other interesting methods}
In addition to the previous models, the literature offers several works that are methodologically interesting. They are briefly described now.

As already mentioned, life event detection is a branch of event identification. The core of the business is therefore the identification of events from a stream of time-stamped documents coming from social networks. In concrete, the job made by Vavliakis, Symeonidis and Mitkas \cite{vavliakis2013event} organizes documents from various sources according to the event they describe, assigning to the event an importance, while the one made by CC Chen, MC Chen and MS Chen \cite{chen2009adaptive} tracks how much activity is related to an event from a global stream of documents. However, also these two models work on global scale, not analyzing a specific user, and they have an implicit issue: they consider the importance of the event based on the \emph{noise} the event brings with him. The more people talk about an event, the more important it is. Therefore every global event, such as The Olympics, will be classified as much more important than a wedding or a birth of a child.

Another interesting study is the one proposed by Li, Ritter and Jurafsky \cite{li2014inferring}, a model-driven system to infer user's attitudes or preferences reasoning over user's attributes and social network graphs. It builds, for every person taken into analysis, a series of predicates for her attributes (location, gender, education), relationships (married, friends) and preferences (what she likes/dislikes), which can be used to detect important events on her timeline or in friends/relatives social profiles. This work is interesting because is the only one that is not completely driven by data and machine learning, but it offers a logical model, and also it combines multiple social networks (Twitter and Google+). On the other hand, of course, this model is not designed to deal with life events.

A last interesting study is about topic sentiment analysis using the hashtag graph in Twitter \cite{wang2011topic}. It demonstrates that hashtags offer additional information to texts, classifying tweets and users in categories: the use of a specific hashtag may be connected with a specific life event. This kind of study, however, has more sense on global scale analysis, like searching for users who show interest in a specific topic: it may be not so useful in a context of life event detection, which is concentrated on a single-user analysis.


\section{The dataset problem}
\label{sec:dataset}
One of the biggest issue in dealing with life events is the lack of data. For an artificial intelligence powered solution a great amount of data is needed, to train a machine learning system and to evaluate it. Furthermore, very few benchmarks exist, so it is hard to understand which is a good result to reach and what are the minimum expectations.

Many users do not share with the world what happens to them in their private life, in fact most of the posts on social networks are not about users' personal life. There is also a strong subjectivity in sharing a life changing event: every user has her way to announce a personal news and it's hard to find a pattern that identifies a life event announcement. For these reasons is not easy to build a dataset big and reliable enough to train the system as good as possible. Furthermore, among the papers cited above, only one \cite{dickinson2015identifying} published the dataset build for the experiment\footnote{\url{reellives.net/rl-data/uploads/2015/06/a692044.csv}}.

The literature presents two different ways to fetch and label the data. Some authors prefer to fetch only contents that contain specific keywords (such as "\emph{engagement}" for marriage) \cite{dickinson2015identifying, khobarekar2013detecting}, labelling each content \emph{by hand} as about or not to the life event itself; some other search for contents randomly, labelling it in a more automatic way, considering a text related to the life event if it contains at least one keyword \cite{choudhury2014personal, di2013detecting, moyanolife}. The first method requires a bigger effort than the second one, because data is selected before the download, and once downloaded is analyzed by a human, who assigns to each post a relation with a life event. On the other hand, bigger work leads to better precision: a human classification is not based on the content only, but also on the meaning of the text. Of course this approach for huge datasets (those used into the cited papers with \emph{automatic} labelling space from tens of thousands to millions of samples) is not recommended. 

In case more than one life event is taken into consideration, this kind of classification becomes a multi-label classification. For example, if marriage and birth of a child are considered, a tweet that speaks about a wedding will have the \emph{marriage} label setted to \texttt{true}, and the \emph{having children} label setted to \texttt{false}. According to \cite{cavalinclassification} and to Wikipedia\footnote{\url{en.wikipedia.org/wiki/Multi-label_classification}}, the easiest way to perform this type of classification is doing a set of binary classification: to do that, a dataset for each life event is necessary. Another problem is represented by how many languages the classifier wants to support: for each of them is necessary a satisfying number of samples, to allow the classifier to learn any patterns or idioms related to each language. In conclusion, if the methodologies exposed by these works were followed, a dataset for each life event and for each language would be necessary. For example, a system that classifies posts about marriage and birth of a child written in english and italian, would need 4 datasets: marriage-english, marriage-italian, child-english and child-italian.

The solution chosen to overcome the language issue was inspired by Tapoi, the user profiling software made by U-Hopper, which works with Wikipedia\footnote{\url{www.wikipedia.org}} contents to understand what a user has talked about in her social profiles \cite{torrero2018wikipedia}. The idea is to use Wikipedia articles to identify words, topics and concepts inside a phrase: each post will contain a set of articles, called \emph{entities}, and categories, called \emph{topics}, which will be the features for the classification. Instead of using the classical bag-of-words with texts, a \emph{bag-of-Wikipedia-entities} will be applied. The procedure is the following: firstly, a dataset in a given language has to be provided; secondly, each post of the dataset has to be analyzed by some semantic analyzer, to extract Wikipedia entities and concepts; thirdly, a machine learning classifier is trained using Wikipedia entities and concepts as feature. Once the classifier is ready, the procedure of analyzing posts with a semantic analyzer must be done with every post to classify. In case a post is written in a language that is not the one of the training set, its entities and concepts have to be translated into those belonging to the Wikipedia version of the training set language.

In addition to that, is possible to use Wikipedia entities not only in texts, but also with images. In fact, there are several image analyzers that are able to find out entities into pictures. In this way is not necessary to create a training set also for images, but it is enough to use the same dataset of texts.

